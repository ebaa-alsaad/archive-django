import os
import re
import hashlib
import logging
import subprocess
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from pdf2image import convert_from_path
import pytesseract
from pyzbar.pyzbar import decode as decode_barcode
import cv2
import numpy as np
from PIL import Image
import fitz  # PyMuPDF - Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø¬Ø¯ÙŠØ¯
from django.core.cache import cache
from .models import Upload, Group
from django.conf import settings
import threading
import time
from datetime import datetime

logger = logging.getLogger(__name__)

class BarcodeOCRService:
    """
    Ø®Ø¯Ù…Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© PDF ÙØ§Ø¦Ù‚Ø© Ø§Ù„Ø³Ø±Ø¹Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PyMuPDF:
    - Ø§ÙƒØªØ´Ø§Ù Ø¨Ø§Ø±ÙƒÙˆØ¯ Ù…Ø¨Ø§Ø´Ø± Ù…Ù† PDF Ø¨Ø¯ÙˆÙ† ØªØ­ÙˆÙŠÙ„ Ù„Ù„ØµÙˆØ±
    - ØªÙ‚Ø³ÙŠÙ… Ø°ÙƒÙŠ Ù„Ù„ØµÙØ­Ø§Øª
    - Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙˆØ§Ø²ÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø©
    - ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ§Ù„Ø£Ø¯Ø§Ø¡
    """

    def __init__(self):
        self._poppler_path = self._find_poppler_path()
        self._lock = threading.Lock()
        self._barcode_cache = {}
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
        self.OCR_ENABLED = False  # ØªØ¹Ø·ÙŠÙ„ OCR Ù„Ù„Ø³Ø±Ø¹Ø© Ø¥Ù„Ø§ Ø¥Ø°Ø§ Ø§Ø­ØªØ¬Ù†Ø§ Ø¥Ù„ÙŠÙ‡
        self.MIN_PAGES_FOR_SAMPLING = 50
        self.MAX_WORKERS = min(4, os.cpu_count() or 2)
        
    def _find_poppler_path(self):
        """Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø³Ø§Ø± poppler"""
        for path in ['/usr/bin', '/usr/local/bin', '/usr/lib/x86_64-linux-gnu']:
            if os.path.exists(os.path.join(path, 'pdftoppm')):
                return path
        return None

    def process_single_pdf(self, upload):
        self.current_upload = upload
        upload_id = upload.id
        start_time = time.time()
        logger.info(f"ğŸš€ Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© ÙØ§Ø¦Ù‚Ø© Ø§Ù„Ø³Ø±Ø¹Ø© Ù„Ù€ upload {upload_id}")
        
        try:
            pdf_path = Path(settings.PRIVATE_MEDIA_ROOT) / upload.stored_filename
            if not pdf_path.exists():
                raise FileNotFoundError(f"PDF file not found: {pdf_path}")

            # Ø§Ù„Ø­Ø§Ù„Ø©: Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
            with self._lock:
                upload.status = 'processing'
                upload.progress = 5
                upload.message = 'Ø¬Ø§Ø±ÙŠ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ù„Ù...'
                upload.save(update_fields=['status', 'progress', 'message'])
            
            # ===== Ø§Ù„Ø®Ø·ÙˆØ© 1: ÙØªØ­ PDF ÙˆØªØ­Ù„ÙŠÙ„ =====
            logger.info(f"ğŸ“– ÙØªØ­ Ø§Ù„Ù…Ù„Ù: {pdf_path}")
            doc = fitz.open(pdf_path)
            total_pages = doc.page_count
            
            logger.info(f"ğŸ“„ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª: {total_pages}")
            
            self._update_upload_progress(upload, 25, f'ØªÙ… ØªØ­Ù…ÙŠÙ„ {total_pages} ØµÙØ­Ø©')
            
            # ===== Ø§Ù„Ø®Ø·ÙˆØ© 2: Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯ Ø§Ù„ÙØ§ØµÙ„ =====
            separator_barcode = self._find_separator_barcode_fast(doc, total_pages)
            logger.info(f"ğŸ” Ø¨Ø§Ø±ÙƒÙˆØ¯ Ø§Ù„ÙØµÙ„: {separator_barcode}")
            
            self._update_upload_progress(upload, 30, f'ØªÙ… ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯ Ø§Ù„ÙØ§ØµÙ„')
            
            # ===== Ø§Ù„Ø®Ø·ÙˆØ© 3: ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙØ­Ø§Øª =====
            self._update_upload_progress(upload, 35, 'Ø¬Ø§Ø±ÙŠ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙØ­Ø§Øª Ø¥Ù„Ù‰ Ø£Ù‚Ø³Ø§Ù…...')
            sections = self._split_pages_fast(doc, separator_barcode, total_pages)
            
            if not sections:
                raise Exception("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ù‚Ø³Ø§Ù… - Ø±Ø¨Ù…Ø§ Ø§Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯ Ø§Ù„ÙØ§ØµÙ„ ØºÙŠØ± ØµØ­ÙŠØ­")
            
            logger.info(f"ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ù‚Ø³Ø§Ù…: {len(sections)}")
            self._update_upload_progress(upload, 50, f'ØªÙ… ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ {len(sections)} Ù‚Ø³Ù…')
            
            # ===== Ø§Ù„Ø®Ø·ÙˆØ© 4: Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª =====
            Group.objects.filter(upload=upload).delete()
            
            self._update_upload_progress(upload, 60, 'Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„ÙØ§Øª PDF Ù„Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª...')
            created_groups = self._create_groups_ultra_fast(doc, sections, separator_barcode, upload)
            
            # Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©
            doc.close()
            
            # ===== Ø§Ù„Ø®Ø·ÙˆØ© 5: ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© =====
            processing_time = time.time() - start_time
            logger.info(f"â±ï¸ ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {processing_time:.2f} Ø«Ø§Ù†ÙŠØ©")
            
            with self._lock:
                upload.status = 'completed'
                upload.progress = 100
                upload.message = f'ØªÙ…Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙÙŠ {processing_time:.1f} Ø«Ø§Ù†ÙŠØ©. Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª: {len(created_groups)}'
                upload.save(update_fields=['status', 'progress', 'message'])
            
            # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            # self._delete_original_if_needed(pdf_path)
            
            logger.info(f"âœ… Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù„Ù€ upload {upload_id}. Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª: {len(created_groups)}")
            return created_groups
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© upload {upload_id}: {e}", exc_info=True)
            with self._lock:
                upload.status = 'failed'
                upload.message = f'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)[:100]}'
                upload.save(update_fields=['status', 'message'])
        raise


    def _find_separator_barcode_fast(self, doc, total_pages):
        """Ø§ÙƒØªØ´Ø§Ù Ø³Ø±ÙŠØ¹ Ù„Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯ Ø§Ù„ÙØ§ØµÙ„"""
        # Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø°ÙƒÙŠØ© Ù„Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯
        check_pages = []
        
        # Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù‡ÙŠ Ø§Ù„Ø£Ù‡Ù…
        check_pages.append(0)
        
        # Ø¨Ø¹Ø¶ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„ÙˆØ³Ø·Ù‰
        if total_pages > 10:
            check_pages.append(total_pages // 2)
        
        # Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø©
        if total_pages > 1:
            check_pages.append(total_pages - 1)
        
        # Ø§Ù„ØµÙØ­Ø§Øª 2-6 (ØºØ§Ù„Ø¨Ø§Ù‹ Ø¨Ù‡Ø§ Ø¨Ø§Ø±ÙƒÙˆØ¯ ÙØ§ØµÙ„)
        for i in range(1, min(6, total_pages)):
            check_pages.append(i)
        
        # ÙØ­Øµ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©
        for page_num in check_pages:
            try:
                barcode = self._extract_barcode_from_pdf_page(doc, page_num)
                if barcode and barcode.strip():
                    logger.info(f"âœ… ÙˆØ¬Ø¯ Ø¨Ø§Ø±ÙƒÙˆØ¯ ÙÙŠ Ø§Ù„ØµÙØ­Ø© {page_num}: {barcode}")
                    return barcode
            except Exception as e:
                logger.debug(f"Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¨Ø§Ø±ÙƒÙˆØ¯ ÙÙŠ Ø§Ù„ØµÙØ­Ø© {page_num}: {e}")
                continue
        
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø¨Ø§Ø±ÙƒÙˆØ¯Ø§Ù‹ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
        default_code = doc.name.split('/')[-1].split('.')[0][:20] or "document"
        logger.info(f"âš ï¸ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨Ø§Ø±ÙƒÙˆØ¯ Ø§ÙØªØ±Ø§Ø¶ÙŠ: {default_code}")
        return default_code
    
    def _extract_barcode_from_pdf_page(self, doc, page_num, dpi=72):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø§Ø±ÙƒÙˆØ¯ Ù…Ù† ØµÙØ­Ø© PDF Ù…Ø¨Ø§Ø´Ø±Ø©"""
    try:
        page = doc[page_num]
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø£ÙˆÙ„Ø§Ù‹ (Ø£Ø³Ø±Ø¹)
        text = page.get_text("text")
        if text:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯ ÙÙŠ Ø§Ù„Ù†Øµ
            patterns = [
                r'\b\d{8,20}\b',  # Ø£Ø±Ù‚Ø§Ù… Ù…Ù† 8 Ø¥Ù„Ù‰ 20 Ø±Ù‚Ù…
                r'Ø¨Ø§Ø±ÙƒÙˆØ¯[\s:]*(\d+)',
                r'Barcode[\s:]*(\d+)',
                r'Code[\s:]*(\d+)',
                r'Ø±Ù‚Ù…[\s:]*(\d+)',
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, text, re.IGNORECASE | re.ARABIC)
                if matches:
                    barcode = str(matches[0]).strip()
                    if len(barcode) >= 8:  # ØªØ£ÙƒØ¯ Ø£Ù†Ù‡ Ø¨Ø§Ø±ÙƒÙˆØ¯ Ø­Ù‚ÙŠÙ‚ÙŠ
                        logger.debug(f"ğŸ“„ ÙˆØ¬Ø¯ Ø¨Ø§Ø±ÙƒÙˆØ¯ ÙÙŠ Ø§Ù„Ù†Øµ (ØµÙØ­Ø© {page_num}): {barcode}")
                        return barcode
        
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ ÙÙŠ Ø§Ù„Ù†ØµØŒ Ù†Ø¨Ø­Ø« ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©
        pix = page.get_pixmap(dpi=dpi)
        
        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© numpy
        img_array = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, pix.n)
        
        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ÙŠ
        if len(img_array.shape) == 3 and img_array.shape[2] == 3:
            gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        else:
            gray = img_array
        
        # Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯
        barcodes = decode_barcode(gray)
        for barcode in barcodes:
            barcode_text = barcode.data.decode("utf-8", errors='ignore').strip()
            if barcode_text:
                logger.debug(f"ğŸ“· ÙˆØ¬Ø¯ Ø¨Ø§Ø±ÙƒÙˆØ¯ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø© (ØµÙØ­Ø© {page_num}): {barcode_text}")
                return barcode_text
        
        return None
        
    except Exception as e:
        logger.debug(f"âŒ ÙØ´Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯ Ù…Ù† Ø§Ù„ØµÙØ­Ø© {page_num}: {e}")
        return None


    def _split_pages_fast(self, doc, separator_barcode, total_pages):
    """ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙØ­Ø§Øª - Ø¥ØµÙ„Ø§Ø­ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ÙƒÙˆØ¯ Laravel"""
    sections = []
    current_section = []
    
    logger.info(f"ğŸ” Ø¨Ø¯Ø¡ ØªÙ‚Ø³ÙŠÙ… {total_pages} ØµÙØ­Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨Ø§Ø±ÙƒÙˆØ¯: {separator_barcode}")
    
    for page_num in range(total_pages):
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯ Ù…Ù† Ø§Ù„ØµÙØ­Ø©
            barcode = self._extract_barcode_from_pdf_page(doc, page_num)
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø¯Ù…
            progress = 40 + ((page_num + 1) / total_pages * 20)
            if page_num % 10 == 0:  # ØªØ­Ø¯ÙŠØ« ÙƒÙ„ 10 ØµÙØ­Ø§Øª
                with self._lock:
                    self._update_upload_progress(self.current_upload, progress, f"Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙØ­Ø© {page_num + 1} Ù…Ù† {total_pages}...")
            
            # Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø© Ù„Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯ (Ù…Ø«Ù„ ÙƒÙˆØ¯ Laravel)
            if barcode and str(barcode).strip() == str(separator_barcode).strip():
                # â­ Ø§Ù„Ù…ÙØªØ§Ø­: Ø¥Ø°Ø§ ÙˆØ¬Ø¯Ù†Ø§ Ø¨Ø§Ø±ÙƒÙˆØ¯ ÙØ§ØµÙ„ØŒ Ù†Ù†Ù‡ÙŠ Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† ÙØ§Ø±ØºØ§Ù‹
                if current_section:
                    sections.append(current_section.copy())
                    logger.debug(f"â• Ù‚Ø³Ù… Ø¬Ø¯ÙŠØ¯ {len(sections)}: Ø§Ù„ØµÙØ­Ø§Øª {current_section}")
                    
                    # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø©
                    with self._lock:
                        self._update_upload_progress(self.current_upload, progress, 
                            f"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {len(sections)} Ù‚Ø³Ù… Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†...")
                
                current_section = []  # Ø§Ø¨Ø¯Ø£ Ù‚Ø³Ù… Ø¬Ø¯ÙŠØ¯ ÙØ§Ø±Øº â­ Ù„Ø§ ØªØ¶ÙŠÙ ØµÙØ­Ø© Ø§Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯
                logger.debug(f"ğŸ”— ØµÙØ­Ø© Ø¨Ø§Ø±ÙƒÙˆØ¯ ÙØ§ØµÙ„: {page_num} - Ø¨Ø¯Ø¡ Ù‚Ø³Ù… Ø¬Ø¯ÙŠØ¯")
            else:
                # ØµÙØ­Ø© Ø¹Ø§Ø¯ÙŠØ© - Ø£Ø¶ÙÙ‡Ø§ Ù„Ù„Ù‚Ø³Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ
                current_section.append(page_num)
                
        except Exception as e:
            logger.debug(f"Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ Ø§Ù„ØµÙØ­Ø© {page_num}: {e}")
            current_section.append(page_num)  # Ø£Ø¶ÙÙ‡Ø§ Ø±ØºÙ… Ø§Ù„Ø®Ø·Ø£
    
    # â­ Ø¥Ø¶Ø§ÙØ© Ø¢Ø®Ø± Ù‚Ø³Ù… Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† ÙØ§Ø±ØºØ§Ù‹ (Ù…Ø«Ù„ ÙƒÙˆØ¯ Laravel)
    if current_section:
        sections.append(current_section)
        logger.debug(f"â• Ù‚Ø³Ù… Ù†Ù‡Ø§Ø¦ÙŠ {len(sections)}: Ø§Ù„ØµÙØ­Ø§Øª {current_section}")
    
    # ØªØµÙÙŠØ© Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„ÙØ§Ø±ØºØ©
    cleaned_sections = [section for section in sections if section]
    
    logger.info(f"âœ… ØªÙ… ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙØ­Ø§Øª Ø¥Ù„Ù‰ {len(cleaned_sections)} Ù‚Ø³Ù…")
    for i, section in enumerate(cleaned_sections):
        logger.info(f"   Ø§Ù„Ù‚Ø³Ù… {i+1}: Ø§Ù„ØµÙØ­Ø§Øª {section}")
    
    return cleaned_sections

    def _update_upload_progress(self, upload, progress, message=''):
    """ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„ØªÙ‚Ø¯Ù… - Ù…Ø´Ø§Ø¨Ù‡ Ù„Ù€ Laravel"""
    if upload:
        try:
            upload.progress = int(progress)
            if hasattr(upload, 'message'):
                upload.message = message
            upload.save(update_fields=['progress', 'message'])
            
            # ØªØ®Ø²ÙŠÙ† ÙÙŠ cache Ù„Ù„ÙˆØµÙˆÙ„ Ø§Ù„Ø³Ø±ÙŠØ¹
            from django.core.cache import cache
            cache_key = f"upload_progress_{upload.id}"
            cache.set(cache_key, {
                'progress': progress,
                'message': message,
                'timestamp': time.time()
            }, 300)  # 5 Ø¯Ù‚Ø§Ø¦Ù‚
            
            logger.debug(f"ğŸ“Š ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø¯Ù…: {progress}% - {message}")
        except Exception as e:
            logger.warning(f"âŒ ÙØ´Ù„ ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø¯Ù…: {e}")



    def _expand_section(self, section_indices, checked_indices, break_point, total_pages):
        """ØªÙˆØ³ÙŠØ¹ Ù‚Ø³Ù… Ù„ÙŠØ´Ù…Ù„ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙØ­Ø§Øª"""
        if not section_indices:
            return []
        
        # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Ø·Ø§Ù‚ Ø§Ù„ØµÙØ­Ø§Øª
        start_page = min(section_indices)
        end_page = max(section_indices)
        
        # Ø¥Ø°Ø§ ÙƒØ§Ù† break_point Ù‚Ø¨Ù„ end_pageØŒ Ø§Ø³ØªØ®Ø¯Ù…Ù‡
        if break_point < end_page and break_point > start_page:
            end_page = break_point - 1
        
        # Ø§Ù„ØªÙˆØ³ÙŠØ¹
        expanded = []
        for page_num in range(start_page, min(end_page + 1, total_pages)):
            expanded.append(page_num)
        
        return expanded
    
    def _create_groups_ultra_fast(self, doc, sections, separator_barcode, upload):
    """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ù…Ø¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ù…Ù† Ø§Ù„Ù†Øµ"""
    created_groups = []
    output_dir = Path(settings.PRIVATE_MEDIA_ROOT) / "groups"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    def extract_group_name_from_page(page_num):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø£ÙˆÙ„ ØµÙØ­Ø© - Ù…Ø´Ø§Ø¨Ù‡ Ù„Ù€ Laravel"""
        try:
            page = doc[page_num]
            text = page.get_text("text")
            
            if not text or len(text.strip()) < 10:
                return None
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±Ù‚Ù… Ø§Ù„Ø³Ù†Ø¯ (Ù…Ø«Ù„ Laravel)
            patterns = [
                r'Ø±Ù‚Ù…\s*Ø§Ù„Ø³Ù†Ø¯\s*[:\-]?\s*(\d{2,})',
                r'Ø§Ù„Ø³Ù†Ø¯\s*[:\-]?\s*(\d{2,})',
                r'Ø³Ù†Ø¯\s*[:\-]?\s*(\d{2,})',
                r'Ø³Ù†Ø¯\s*Ø±Ù‚Ù…\s*[:\-]?\s*(\d{2,})',
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, text, re.IGNORECASE | re.ARABIC)
                if matches:
                    return f"Ø³Ù†Ø¯_{matches[0]}"
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±Ù‚Ù… Ø§Ù„Ù‚ÙŠØ¯
            qeed_patterns = [
                r'Ø±Ù‚Ù…\s*Ø§Ù„Ù‚ÙŠØ¯\s*[:\-]?\s*(\d+)',
                r'Ø§Ù„Ù‚ÙŠØ¯\s*[:\-]?\s*(\d+)',
                r'Ù‚ÙŠØ¯\s*[:\-]?\s*(\d+)',
            ]
            
            for pattern in qeed_patterns:
                matches = re.findall(pattern, text, re.IGNORECASE | re.ARABIC)
                if matches:
                    return f"Ù‚ÙŠØ¯_{matches[0]}"
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ØªØ§Ø±ÙŠØ®
            date_patterns = [
                r'(\d{2}/\d{2}/\d{4})',
                r'(\d{2}-\d{2}-\d{4})',
                r'(\d{4}-\d{2}-\d{2})',
            ]
            
            for pattern in date_patterns:
                matches = re.findall(pattern, text)
                if matches:
                    return f"ØªØ§Ø±ÙŠØ®_{matches[0].replace('/', '-')}"
            
            return None
            
        except Exception as e:
            logger.debug(f"ÙØ´Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø§Ø³Ù… Ù…Ù† Ø§Ù„ØµÙØ­Ø© {page_num}: {e}")
            return None
    
    def create_single_group(idx, pages):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© ÙˆØ§Ø­Ø¯Ø©"""
        try:
            if not pages:
                return None
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø£ÙˆÙ„ ØµÙØ­Ø©
            group_name = extract_group_name_from_page(pages[0])
            
            # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø§Ø³Ù…Ø§Ù‹ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ø³Ù… Ø§ÙØªØ±Ø§Ø¶ÙŠ
            if not group_name:
                group_name = f"{separator_barcode}_{idx+1}"
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø§Ø³Ù…
            group_name = self._sanitize_filename(group_name)
            filename_safe = f"{group_name}.pdf"
            output_path = output_dir / filename_safe
            
            # Ø¥Ù†Ø´Ø§Ø¡ PDF Ø¬Ø¯ÙŠØ¯
            new_doc = fitz.open()
            for page_num in pages:
                if page_num < doc.page_count:
                    new_doc.insert_pdf(doc, from_page=page_num, to_page=page_num)
            
            # Ø­ÙØ¸ Ù…Ø¹ Ø¶ØºØ·
            new_doc.save(output_path, deflate=True, garbage=4, clean=True)
            new_doc.close()
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù
            if not output_path.exists() or output_path.stat().st_size < 10000:  # Ø£Ù‚Ù„ Ù…Ù† 10KB
                logger.warning(f"ğŸ“„ Ù…Ù„Ù ØµØºÙŠØ± Ø¬Ø¯Ø§Ù‹: {output_path} ({output_path.stat().st_size} bytes)")
                return None
            
            # Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            group = Group.objects.create(
                code=separator_barcode,
                pdf_path=f"groups/{filename_safe}",
                pages_count=len(pages),
                user=upload.user,
                upload=upload,
                filename=filename_safe,
                name=group_name
            )
            
            logger.info(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© {idx+1}: {group_name} ({len(pages)} ØµÙØ­Ø©)")
            return group
            
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© {idx+1}: {e}")
            return None
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ Ù…Ø¹ ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø¯Ù…
    total_sections = len(sections)
    with ThreadPoolExecutor(max_workers=self.MAX_WORKERS) as executor:
        futures = []
        for idx, pages in enumerate(sections):
            future = executor.submit(create_single_group, idx, pages)
            futures.append(future)
        
        # Ø¬Ù…Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø¹ ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø¯Ù…
        completed = 0
        for future in as_completed(futures):
            try:
                result = future.result(timeout=30)
                if result:
                    created_groups.append(result)
                    completed += 1
                    
                    # ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø¯Ù…
                    progress = 60 + int((completed / total_sections) * 40)
                    self._update_upload_progress(upload, progress, 
                        f"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {completed} Ù…Ù† {total_sections} Ù…Ø¬Ù…ÙˆØ¹Ø©...")
                        
            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù‚Ø³Ù…: {e}")
    
    return created_groups


    def _sanitize_filename(self, filename):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù"""
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø­Ø±Ù ØºÙŠØ± Ø§Ù„Ø¢Ù…Ù†Ø©
        filename = re.sub(r'[^\w\-_\.]', '_', filename)
        # ØªÙ‚ØµÙŠØ± Ø¥Ø°Ø§ Ø·Ø§Ù„
        if len(filename) > 80:
            name, ext = os.path.splitext(filename)
            filename = name[:75] + ext
        return filename or "document"
    
    def _delete_original_if_needed(self, pdf_path):
        """Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù†Ø§Ø¬Ø­Ø©"""
        try:
            if pdf_path.exists():
                # ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù Ø£ÙˆÙ„Ø§Ù‹
                file_size = pdf_path.stat().st_size
                if file_size > 50 * 1024 * 1024:  # Ø£ÙƒØ¨Ø± Ù…Ù† 50MB
                    logger.info(f"âš ï¸ Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ Ø§Ù„ÙƒØ¨ÙŠØ±: {file_size / (1024*1024):.1f}MB")
                    return
                
                pdf_path.unlink()
                logger.info(f"ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ: {pdf_path}")
        except Exception as e:
            logger.warning(f"âš ï¸ ÙØ´Ù„ Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ: {e}")

    def process_multiple_pdfs_async(self, uploads):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ø¯Ø© Ù…Ù„ÙØ§Øª Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†"""
        import asyncio
        import aiohttp
        
        async def process_upload_async(upload):
            """Ù…Ø¹Ø§Ù„Ø¬Ø© upload ÙˆØ§Ø­Ø¯Ø© Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†"""
            try:
                groups = await asyncio.to_thread(self.process_single_pdf, upload)
                return upload.id, {"success": True, "groups": groups}
            except Exception as e:
                return upload.id, {"success": False, "error": str(e)}
        
        async def main():
            """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠØ©"""
            tasks = [process_upload_async(upload) for upload in uploads]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            processed_results = {}
            for result in results:
                if isinstance(result, tuple) and len(result) == 2:
                    upload_id, data = result
                    processed_results[upload_id] = data
            
            return processed_results
        
        # ØªØ´ØºÙŠÙ„ ÙÙŠ loop Ø¬Ø¯ÙŠØ¯
        import asyncio
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            results = loop.run_until_complete(main())
        finally:
            loop.close()
        
        return results