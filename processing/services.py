import os
import re
import hashlib
import logging
import subprocess
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from pdf2image import convert_from_path
import pytesseract
from pyzbar.pyzbar import decode as decode_barcode
import cv2
import numpy as np
from PIL import Image
import fitz  # PyMuPDF - Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø¬Ø¯ÙŠØ¯
from django.core.cache import cache
from .models import Upload, Group
from django.conf import settings
import threading
import time
from datetime import datetime

logger = logging.getLogger(__name__)

class UltraFastBarcodeOCRService:
    """
    Ø®Ø¯Ù…Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© PDF ÙØ§Ø¦Ù‚Ø© Ø§Ù„Ø³Ø±Ø¹Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PyMuPDF:
    - Ø§ÙƒØªØ´Ø§Ù Ø¨Ø§Ø±ÙƒÙˆØ¯ Ù…Ø¨Ø§Ø´Ø± Ù…Ù† PDF Ø¨Ø¯ÙˆÙ† ØªØ­ÙˆÙŠÙ„ Ù„Ù„ØµÙˆØ±
    - ØªÙ‚Ø³ÙŠÙ… Ø°ÙƒÙŠ Ù„Ù„ØµÙØ­Ø§Øª
    - Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙˆØ§Ø²ÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø©
    - ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ§Ù„Ø£Ø¯Ø§Ø¡
    """

    def __init__(self):
        self._poppler_path = self._find_poppler_path()
        self._lock = threading.Lock()
        self._barcode_cache = {}
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
        self.OCR_ENABLED = False  # ØªØ¹Ø·ÙŠÙ„ OCR Ù„Ù„Ø³Ø±Ø¹Ø© Ø¥Ù„Ø§ Ø¥Ø°Ø§ Ø§Ø­ØªØ¬Ù†Ø§ Ø¥Ù„ÙŠÙ‡
        self.MIN_PAGES_FOR_SAMPLING = 50
        self.MAX_WORKERS = min(4, os.cpu_count() or 2)
        
    def _find_poppler_path(self):
        """Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø³Ø§Ø± poppler"""
        for path in ['/usr/bin', '/usr/local/bin', '/usr/lib/x86_64-linux-gnu']:
            if os.path.exists(os.path.join(path, 'pdftoppm')):
                return path
        return None

    def process_single_pdf(self, upload):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© PDF ÙˆØ§Ø­Ø¯Ø© - ÙØ§Ø¦Ù‚Ø© Ø§Ù„Ø³Ø±Ø¹Ø©"""
        upload_id = upload.id
        start_time = time.time()
        logger.info(f"ğŸš€ Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© ÙØ§Ø¦Ù‚Ø© Ø§Ù„Ø³Ø±Ø¹Ø© Ù„Ù€ upload {upload_id}")
        
        try:
            pdf_path = Path(settings.PRIVATE_MEDIA_ROOT) / upload.stored_filename
            if not pdf_path.exists():
                raise FileNotFoundError(f"PDF file not found: {pdf_path}")

            # Ø§Ù„Ø­Ø§Ù„Ø©: Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
            with self._lock:
                upload.status = 'processing'
                upload.progress = 10
                upload.save(update_fields=['status', 'progress'])
            
            # ===== Ø§Ù„Ø®Ø·ÙˆØ© 1: ÙØªØ­ PDF ÙˆØªØ­Ù„ÙŠÙ„ Ø³Ø±ÙŠØ¹ =====
            logger.info(f"ğŸ“– ÙØªØ­ Ø§Ù„Ù…Ù„Ù: {pdf_path}")
            doc = fitz.open(pdf_path)
            total_pages = doc.page_count
            
            logger.info(f"ğŸ“„ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª: {total_pages}")
            
            upload.progress = 20
            upload.save(update_fields=['progress'])
            
            # ===== Ø§Ù„Ø®Ø·ÙˆØ© 2: Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯Ø§Øª Ø§Ù„Ø°ÙƒÙŠ =====
            separator_barcode = self._find_separator_barcode_fast(doc, total_pages)
            logger.info(f"ğŸ” Ø¨Ø§Ø±ÙƒÙˆØ¯ Ø§Ù„ÙØµÙ„: {separator_barcode}")
            
            upload.progress = 40
            upload.save(update_fields=['progress'])
            
            # ===== Ø§Ù„Ø®Ø·ÙˆØ© 3: ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ø³Ø±ÙŠØ¹ =====
            sections = self._split_pages_fast(doc, separator_barcode, total_pages)
            logger.info(f"ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ù‚Ø³Ø§Ù…: {len(sections)}")
            
            upload.progress = 60
            upload.save(update_fields=['progress'])
            
            # ===== Ø§Ù„Ø®Ø·ÙˆØ© 4: Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ =====
            Group.objects.filter(upload=upload).delete()
            
            created_groups = self._create_groups_ultra_fast(doc, sections, separator_barcode, upload)
            
            # Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©
            doc.close()
            
            # ===== Ø§Ù„Ø®Ø·ÙˆØ© 5: ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© =====
            processing_time = time.time() - start_time
            logger.info(f"â±ï¸ ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {processing_time:.2f} Ø«Ø§Ù†ÙŠØ©")
            
            with self._lock:
                upload.status = 'completed'
                upload.progress = 100
                upload.message = f'ØªÙ…Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙÙŠ {processing_time:.1f} Ø«Ø§Ù†ÙŠØ©. Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª: {len(created_groups)}'
                upload.save(update_fields=['status', 'progress', 'message'])
            
            # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ
            self._delete_original_if_needed(pdf_path)
            
            logger.info(f"âœ… Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù„Ù€ upload {upload_id}. Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª: {len(created_groups)}")
            return created_groups
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© upload {upload_id}: {e}", exc_info=True)
            with self._lock:
                upload.status = 'failed'
                upload.message = f'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)[:100]}'
                upload.save(update_fields=['status', 'message'])
            raise
    
    def _find_separator_barcode_fast(self, doc, total_pages):
        """Ø§ÙƒØªØ´Ø§Ù Ø³Ø±ÙŠØ¹ Ù„Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯ Ø§Ù„ÙØ§ØµÙ„"""
        # Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø°ÙƒÙŠØ© Ù„Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯
        check_pages = []
        
        # Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù‡ÙŠ Ø§Ù„Ø£Ù‡Ù…
        check_pages.append(0)
        
        # Ø¨Ø¹Ø¶ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„ÙˆØ³Ø·Ù‰
        if total_pages > 10:
            check_pages.append(total_pages // 2)
        
        # Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø©
        if total_pages > 1:
            check_pages.append(total_pages - 1)
        
        # Ø§Ù„ØµÙØ­Ø§Øª 2-6 (ØºØ§Ù„Ø¨Ø§Ù‹ Ø¨Ù‡Ø§ Ø¨Ø§Ø±ÙƒÙˆØ¯ ÙØ§ØµÙ„)
        for i in range(1, min(6, total_pages)):
            check_pages.append(i)
        
        # ÙØ­Øµ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©
        for page_num in check_pages:
            try:
                barcode = self._extract_barcode_from_pdf_page(doc, page_num)
                if barcode and barcode.strip():
                    logger.info(f"âœ… ÙˆØ¬Ø¯ Ø¨Ø§Ø±ÙƒÙˆØ¯ ÙÙŠ Ø§Ù„ØµÙØ­Ø© {page_num}: {barcode}")
                    return barcode
            except Exception as e:
                logger.debug(f"Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¨Ø§Ø±ÙƒÙˆØ¯ ÙÙŠ Ø§Ù„ØµÙØ­Ø© {page_num}: {e}")
                continue
        
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø¨Ø§Ø±ÙƒÙˆØ¯Ø§Ù‹ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
        default_code = doc.name.split('/')[-1].split('.')[0][:20] or "document"
        logger.info(f"âš ï¸ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨Ø§Ø±ÙƒÙˆØ¯ Ø§ÙØªØ±Ø§Ø¶ÙŠ: {default_code}")
        return default_code
    
    def _extract_barcode_from_pdf_page(self, doc, page_num, dpi=72):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø§Ø±ÙƒÙˆØ¯ Ù…Ù† ØµÙØ­Ø© PDF Ù…Ø¨Ø§Ø´Ø±Ø©"""
        try:
            page = doc[page_num]
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† PDF Ø¨Ø¯Ù‚Ø© Ù…Ù†Ø®ÙØ¶Ø© Ù„Ù„Ø³Ø±Ø¹Ø©
            pix = page.get_pixmap(dpi=dpi)
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© numpy Ù…Ø¨Ø§Ø´Ø±Ø© (Ø¨Ø¯ÙˆÙ† PIL)
            img_array = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, pix.n)
            
            # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ØµÙˆØ±Ø© Ù…Ù„ÙˆÙ†Ø© (RGB)
            if pix.n == 4:  # RGBA
                # ØªØ¬Ø§Ù‡Ù„ Ù‚Ù†Ø§Ø© Ø£Ù„ÙØ§
                img_array = img_array[:, :, :3]
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ÙŠ
            if len(img_array.shape) == 3 and img_array.shape[2] == 3:
                gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
            else:
                gray = img_array
            
            # Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯
            barcodes = decode_barcode(gray)
            for barcode in barcodes:
                return barcode.data.decode("utf-8", errors='ignore')
            
            # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø¨Ø§Ø±ÙƒÙˆØ¯Ø§Ù‹ØŒ Ø¬Ø±Ø¨ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ
            try:
                text = page.get_text("text")
                if text:
                    # Ø¨Ø­Ø« Ø¹Ù† Ø£Ù†Ù…Ø§Ø· Ø¨Ø§Ø±ÙƒÙˆØ¯ ÙÙŠ Ø§Ù„Ù†Øµ
                    patterns = [
                        r'\b\d{8,15}\b',  # Ø£Ø±Ù‚Ø§Ù… Ø·ÙˆÙŠÙ„Ø© (Ù…Ø«Ù„ Ø§Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯)
                        r'CODE[\s:]*(\d+)',
                        r'Ø¨Ø§Ø±ÙƒÙˆØ¯[\s:]*(\d+)',
                        r'Barcode[\s:]*(\d+)',
                    ]
                    
                    for pattern in patterns:
                        matches = re.findall(pattern, text, re.IGNORECASE)
                        if matches:
                            return matches[0]
            except:
                pass
            
            return None
            
        except Exception as e:
            logger.debug(f"ÙØ´Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯ Ù…Ù† Ø§Ù„ØµÙØ­Ø© {page_num}: {e}")
            return None
    
    def _split_pages_fast(self, doc, separator_barcode, total_pages):
        """ØªÙ‚Ø³ÙŠÙ… Ø³Ø±ÙŠØ¹ Ù„Ù„ØµÙØ­Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø°ÙƒÙŠØ©"""
        sections = []
        current_section = []
        
        # ØªÙ‚Ù„ÙŠÙ„ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„ØªÙŠ Ù†ÙØ­ØµÙ‡Ø§
        if total_pages > 100:
            # Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©: ÙØ­Øµ Ø¹ÙŠÙ†Ø© ÙÙ‚Ø·
            step = max(1, total_pages // 50)  # ÙØ­Øµ 2% Ù…Ù† Ø§Ù„ØµÙØ­Ø§Øª
            pages_to_check = list(range(0, total_pages, step))
            logger.info(f"ğŸ” ÙØ­Øµ Ø¹ÙŠÙ†Ø© Ù…Ù† {len(pages_to_check)} ØµÙØ­Ø© Ù…Ù† Ø£ØµÙ„ {total_pages}")
        else:
            # Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµØºÙŠØ±Ø©: ÙØ­Øµ ÙƒÙ„ Ø§Ù„ØµÙØ­Ø§Øª
            pages_to_check = range(total_pages)
        
        for i, page_num in enumerate(pages_to_check):
            try:
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯
                barcode = self._extract_barcode_from_pdf_page(doc, page_num, dpi=50)  # Ø¯Ù‚Ø© Ù…Ù†Ø®ÙØ¶Ø© Ù„Ù„Ø³Ø±Ø¹Ø©
                
                if barcode == separator_barcode:
                    if current_section:
                        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù‚Ø³Ù… Ù…Ø¹ ØªÙˆØ³ÙŠØ¹Ù‡ Ù„ÙŠØ´Ù…Ù„ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
                        full_section = self._expand_section(current_section, pages_to_check, page_num, total_pages)
                        sections.append(full_section)
                        logger.debug(f"â• Ù‚Ø³Ù… Ø¬Ø¯ÙŠØ¯: {len(full_section)} ØµÙØ­Ø©")
                    current_section = []
                else:
                    current_section.append(page_num)
                    
            except Exception as e:
                logger.debug(f"Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ Ø§Ù„ØµÙØ­Ø© {page_num}: {e}")
                current_section.append(page_num)  # Ø£Ø¶ÙÙ‡Ø§ Ø±ØºÙ… Ø§Ù„Ø®Ø·Ø£
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø£Ø®ÙŠØ±
        if current_section:
            full_section = self._expand_section(current_section, pages_to_check, total_pages, total_pages)
            sections.append(full_section)
        
        # ØªØ±ØªÙŠØ¨ ÙˆØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ù‚Ø³Ø§Ù…
        cleaned_sections = []
        for section in sections:
            if section:  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„ÙØ§Ø±ØºØ©
                # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª ÙˆØªØ±ØªÙŠØ¨ Ø§Ù„ØµÙØ­Ø§Øª
                unique_pages = sorted(list(set(section)))
                if unique_pages:  # ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù‚Ø³Ù… ØºÙŠØ± ÙØ§Ø±Øº
                    cleaned_sections.append(unique_pages)
        
        return cleaned_sections
    
    def _expand_section(self, section_indices, checked_indices, break_point, total_pages):
        """ØªÙˆØ³ÙŠØ¹ Ù‚Ø³Ù… Ù„ÙŠØ´Ù…Ù„ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙØ­Ø§Øª"""
        if not section_indices:
            return []
        
        # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Ø·Ø§Ù‚ Ø§Ù„ØµÙØ­Ø§Øª
        start_page = min(section_indices)
        end_page = max(section_indices)
        
        # Ø¥Ø°Ø§ ÙƒØ§Ù† break_point Ù‚Ø¨Ù„ end_pageØŒ Ø§Ø³ØªØ®Ø¯Ù…Ù‡
        if break_point < end_page and break_point > start_page:
            end_page = break_point - 1
        
        # Ø§Ù„ØªÙˆØ³ÙŠØ¹
        expanded = []
        for page_num in range(start_page, min(end_page + 1, total_pages)):
            expanded.append(page_num)
        
        return expanded
    
    def _create_groups_ultra_fast(self, doc, sections, separator_barcode, upload):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨Ø£Ù‚ØµÙ‰ Ø³Ø±Ø¹Ø©"""
        created_groups = []
        output_dir = Path(settings.PRIVATE_MEDIA_ROOT) / "groups"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        def create_single_group(idx, pages):
            """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© ÙˆØ§Ø­Ø¯Ø©"""
            try:
                if not pages:
                    return None
                
                # Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
                timestamp = datetime.now().strftime("%H%M%S")
                filename = f"{separator_barcode}_{idx+1}_{timestamp}"
                filename = self._sanitize_filename(filename)
                filename_safe = f"{filename}.pdf"
                output_path = output_dir / filename_safe
                
                # Ø¥Ù†Ø´Ø§Ø¡ PDF Ø¬Ø¯ÙŠØ¯
                new_doc = fitz.open()
                for page_num in pages:
                    if page_num < doc.page_count:
                        new_doc.insert_pdf(doc, from_page=page_num, to_page=page_num)
                
                # Ø­ÙØ¸ Ù…Ø¹ Ø¶ØºØ· Ù…ØªÙ‚Ø¯Ù…
                new_doc.save(
                    output_path,
                    deflate=True,        # Ø¶ØºØ·
                    garbage=4,          # ØªÙ†Ø¸ÙŠÙ
                    clean=True,         # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù‡ÙŠÙƒÙ„
                    deflate_images=True, # Ø¶ØºØ· Ø§Ù„ØµÙˆØ±
                    deflate_fonts=True  # Ø¶ØºØ· Ø§Ù„Ø®Ø·ÙˆØ·
                )
                new_doc.close()
                
                # Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                group = Group.objects.create(
                    code=separator_barcode,
                    pdf_path=f"groups/{filename_safe}",
                    pages_count=len(pages),
                    user=upload.user,
                    upload=upload,
                    filename=filename_safe,
                    name=filename
                )
                
                return group
                
            except Exception as e:
                logger.error(f"âŒ ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© {idx+1}: {e}")
                return None
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ Ù…Ø¹ ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø¯Ù…
        with ThreadPoolExecutor(max_workers=self.MAX_WORKERS) as executor:
            futures = []
            for idx, pages in enumerate(sections):
                future = executor.submit(create_single_group, idx, pages)
                futures.append(future)
            
            # Ø¬Ù…Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø¹ ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø¯Ù…
            completed = 0
            for future in as_completed(futures):
                try:
                    result = future.result(timeout=30)
                    if result:
                        created_groups.append(result)
                        completed += 1
                        
                        # ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø¯Ù…
                        if len(sections) > 0:
                            progress = 60 + int((completed / len(sections)) * 40)
                            with self._lock:
                                upload.progress = min(progress, 99)
                                upload.save(update_fields=['progress'])
                                
                except Exception as e:
                    logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù‚Ø³Ù…: {e}")
        
        return created_groups
    
    def _sanitize_filename(self, filename):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù"""
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø­Ø±Ù ØºÙŠØ± Ø§Ù„Ø¢Ù…Ù†Ø©
        filename = re.sub(r'[^\w\-_\.]', '_', filename)
        # ØªÙ‚ØµÙŠØ± Ø¥Ø°Ø§ Ø·Ø§Ù„
        if len(filename) > 80:
            name, ext = os.path.splitext(filename)
            filename = name[:75] + ext
        return filename or "document"
    
    def _delete_original_if_needed(self, pdf_path):
        """Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù†Ø§Ø¬Ø­Ø©"""
        try:
            if pdf_path.exists():
                # ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù Ø£ÙˆÙ„Ø§Ù‹
                file_size = pdf_path.stat().st_size
                if file_size > 50 * 1024 * 1024:  # Ø£ÙƒØ¨Ø± Ù…Ù† 50MB
                    logger.info(f"âš ï¸ Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ Ø§Ù„ÙƒØ¨ÙŠØ±: {file_size / (1024*1024):.1f}MB")
                    return
                
                pdf_path.unlink()
                logger.info(f"ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ: {pdf_path}")
        except Exception as e:
            logger.warning(f"âš ï¸ ÙØ´Ù„ Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ: {e}")

    def process_multiple_pdfs_async(self, uploads):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ø¯Ø© Ù…Ù„ÙØ§Øª Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†"""
        import asyncio
        import aiohttp
        
        async def process_upload_async(upload):
            """Ù…Ø¹Ø§Ù„Ø¬Ø© upload ÙˆØ§Ø­Ø¯Ø© Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†"""
            try:
                groups = await asyncio.to_thread(self.process_single_pdf, upload)
                return upload.id, {"success": True, "groups": groups}
            except Exception as e:
                return upload.id, {"success": False, "error": str(e)}
        
        async def main():
            """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠØ©"""
            tasks = [process_upload_async(upload) for upload in uploads]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            processed_results = {}
            for result in results:
                if isinstance(result, tuple) and len(result) == 2:
                    upload_id, data = result
                    processed_results[upload_id] = data
            
            return processed_results
        
        # ØªØ´ØºÙŠÙ„ ÙÙŠ loop Ø¬Ø¯ÙŠØ¯
        import asyncio
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            results = loop.run_until_complete(main())
        finally:
            loop.close()
        
        return results