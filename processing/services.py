import os
import re
import hashlib
import logging
import subprocess
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from pdf2image import convert_from_path
import pytesseract
from pyzbar.pyzbar import decode as decode_barcode
import cv2
import numpy as np
from PIL import Image
import fitz  # PyMuPDF - Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø¬Ø¯ÙŠØ¯
from django.core.cache import cache
from .models import Upload, Group
from django.conf import settings
import threading
import time
from datetime import datetime

logger = logging.getLogger(__name__)

class BarcodeOCRService:
    """
    Ø®Ø¯Ù…Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© PDF ÙØ§Ø¦Ù‚Ø© Ø§Ù„Ø³Ø±Ø¹Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PyMuPDF:
    - Ø§ÙƒØªØ´Ø§Ù Ø¨Ø§Ø±ÙƒÙˆØ¯ Ù…Ø¨Ø§Ø´Ø± Ù…Ù† PDF Ø¨Ø¯ÙˆÙ† ØªØ­ÙˆÙŠÙ„ Ù„Ù„ØµÙˆØ±
    - ØªÙ‚Ø³ÙŠÙ… Ø°ÙƒÙŠ Ù„Ù„ØµÙØ­Ø§Øª
    - Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙˆØ§Ø²ÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø©
    - ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ§Ù„Ø£Ø¯Ø§Ø¡
    """

    def __init__(self):
        self._poppler_path = self._find_poppler_path()
        self._lock = threading.Lock()
        self._barcode_cache = {}
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
        self.OCR_ENABLED = False  # ØªØ¹Ø·ÙŠÙ„ OCR Ù„Ù„Ø³Ø±Ø¹Ø© Ø¥Ù„Ø§ Ø¥Ø°Ø§ Ø§Ø­ØªØ¬Ù†Ø§ Ø¥Ù„ÙŠÙ‡
        self.MIN_PAGES_FOR_SAMPLING = 50
        self.MAX_WORKERS = min(4, os.cpu_count() or 2)
        
    def _find_poppler_path(self):
        """Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø³Ø§Ø± poppler"""
        for path in ['/usr/bin', '/usr/local/bin', '/usr/lib/x86_64-linux-gnu']:
            if os.path.exists(os.path.join(path, 'pdftoppm')):
                return path
        return None

    def process_single_pdf(self, upload):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© PDF ÙˆØ§Ø­Ø¯Ø© - ÙØ§Ø¦Ù‚Ø© Ø§Ù„Ø³Ø±Ø¹Ø©"""
        upload_id = upload.id
        start_time = time.time()
        logger.info(f"ğŸš€ Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© ÙØ§Ø¦Ù‚Ø© Ø§Ù„Ø³Ø±Ø¹Ø© Ù„Ù€ upload {upload_id}")
        
        try:
            pdf_path = Path(settings.PRIVATE_MEDIA_ROOT) / upload.stored_filename
            if not pdf_path.exists():
                raise FileNotFoundError(f"PDF file not found: {pdf_path}")

            # Ø§Ù„Ø­Ø§Ù„Ø©: Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
            with self._lock:
                upload.status = 'processing'
                upload.progress = 10
                upload.save(update_fields=['status', 'progress'])
            
            # ===== Ø§Ù„Ø®Ø·ÙˆØ© 1: ÙØªØ­ PDF ÙˆØªØ­Ù„ÙŠÙ„ Ø³Ø±ÙŠØ¹ =====
            logger.info(f"ğŸ“– ÙØªØ­ Ø§Ù„Ù…Ù„Ù: {pdf_path}")
            doc = fitz.open(pdf_path)
            total_pages = doc.page_count
            
            logger.info(f"ğŸ“„ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª: {total_pages}")
            
            upload.progress = 20
            upload.save(update_fields=['progress'])
            
            # ===== Ø§Ù„Ø®Ø·ÙˆØ© 2: Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯Ø§Øª Ø§Ù„Ø°ÙƒÙŠ =====
            separator_barcode = self._find_separator_barcode_fast(doc, total_pages)
            logger.info(f"ğŸ” Ø¨Ø§Ø±ÙƒÙˆØ¯ Ø§Ù„ÙØµÙ„: {separator_barcode}")
            
            upload.progress = 40
            upload.save(update_fields=['progress'])
            
            # ===== Ø§Ù„Ø®Ø·ÙˆØ© 3: ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ø³Ø±ÙŠØ¹ =====
            sections = self._split_pages_fast(doc, separator_barcode, total_pages)
            logger.info(f"ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ù‚Ø³Ø§Ù…: {len(sections)}")
            
            upload.progress = 60
            upload.save(update_fields=['progress'])
            
            # ===== Ø§Ù„Ø®Ø·ÙˆØ© 4: Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ =====
            Group.objects.filter(upload=upload).delete()
            
            created_groups = self._create_groups_ultra_fast(doc, sections, separator_barcode, upload)
            
            # Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©
            doc.close()
            
            # ===== Ø§Ù„Ø®Ø·ÙˆØ© 5: ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© =====
            processing_time = time.time() - start_time
            logger.info(f"â±ï¸ ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {processing_time:.2f} Ø«Ø§Ù†ÙŠØ©")
            
            with self._lock:
                upload.status = 'completed'
                upload.progress = 100
                upload.message = f'ØªÙ…Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙÙŠ {processing_time:.1f} Ø«Ø§Ù†ÙŠØ©. Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª: {len(created_groups)}'
                upload.save(update_fields=['status', 'progress', 'message'])
            
            # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ
            self._delete_original_if_needed(pdf_path)
            
            logger.info(f"âœ… Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù„Ù€ upload {upload_id}. Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª: {len(created_groups)}")
            return created_groups
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© upload {upload_id}: {e}", exc_info=True)
            with self._lock:
                upload.status = 'failed'
                upload.message = f'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)[:100]}'
                upload.save(update_fields=['status', 'message'])
            raise
    
    def _find_separator_barcode_fast(self, doc, total_pages):
        """Ø§ÙƒØªØ´Ø§Ù Ø³Ø±ÙŠØ¹ Ù„Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯ Ø§Ù„ÙØ§ØµÙ„"""
        # Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø°ÙƒÙŠØ© Ù„Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯
        check_pages = []
        
        # Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù‡ÙŠ Ø§Ù„Ø£Ù‡Ù…
        check_pages.append(0)
        
        # Ø¨Ø¹Ø¶ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„ÙˆØ³Ø·Ù‰
        if total_pages > 10:
            check_pages.append(total_pages // 2)
        
        # Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø©
        if total_pages > 1:
            check_pages.append(total_pages - 1)
        
        # Ø§Ù„ØµÙØ­Ø§Øª 2-6 (ØºØ§Ù„Ø¨Ø§Ù‹ Ø¨Ù‡Ø§ Ø¨Ø§Ø±ÙƒÙˆØ¯ ÙØ§ØµÙ„)
        for i in range(1, min(6, total_pages)):
            check_pages.append(i)
        
        # ÙØ­Øµ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©
        for page_num in check_pages:
            try:
                barcode = self._extract_barcode_from_pdf_page(doc, page_num)
                if barcode and barcode.strip():
                    logger.info(f"âœ… ÙˆØ¬Ø¯ Ø¨Ø§Ø±ÙƒÙˆØ¯ ÙÙŠ Ø§Ù„ØµÙØ­Ø© {page_num}: {barcode}")
                    return barcode
            except Exception as e:
                logger.debug(f"Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¨Ø§Ø±ÙƒÙˆØ¯ ÙÙŠ Ø§Ù„ØµÙØ­Ø© {page_num}: {e}")
                continue
        
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø¨Ø§Ø±ÙƒÙˆØ¯Ø§Ù‹ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
        default_code = doc.name.split('/')[-1].split('.')[0][:20] or "document"
        logger.info(f"âš ï¸ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨Ø§Ø±ÙƒÙˆØ¯ Ø§ÙØªØ±Ø§Ø¶ÙŠ: {default_code}")
        return default_code
    
    def _extract_barcode_from_pdf_page(self, doc, page_num, dpi=72):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø§Ø±ÙƒÙˆØ¯ Ù…Ù† ØµÙØ­Ø© PDF Ù…Ø¨Ø§Ø´Ø±Ø©"""
    try:
        page = doc[page_num]
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø£ÙˆÙ„Ø§Ù‹ (Ø£Ø³Ø±Ø¹)
        text = page.get_text("text")
        if text:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯ ÙÙŠ Ø§Ù„Ù†Øµ
            patterns = [
                r'\b\d{8,20}\b',  # Ø£Ø±Ù‚Ø§Ù… Ù…Ù† 8 Ø¥Ù„Ù‰ 20 Ø±Ù‚Ù…
                r'Ø¨Ø§Ø±ÙƒÙˆØ¯[\s:]*(\d+)',
                r'Barcode[\s:]*(\d+)',
                r'Code[\s:]*(\d+)',
                r'Ø±Ù‚Ù…[\s:]*(\d+)',
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, text, re.IGNORECASE | re.ARABIC)
                if matches:
                    barcode = str(matches[0]).strip()
                    if len(barcode) >= 8:  # ØªØ£ÙƒØ¯ Ø£Ù†Ù‡ Ø¨Ø§Ø±ÙƒÙˆØ¯ Ø­Ù‚ÙŠÙ‚ÙŠ
                        logger.debug(f"ğŸ“„ ÙˆØ¬Ø¯ Ø¨Ø§Ø±ÙƒÙˆØ¯ ÙÙŠ Ø§Ù„Ù†Øµ (ØµÙØ­Ø© {page_num}): {barcode}")
                        return barcode
        
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ ÙÙŠ Ø§Ù„Ù†ØµØŒ Ù†Ø¨Ø­Ø« ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©
        pix = page.get_pixmap(dpi=dpi)
        
        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© numpy
        img_array = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, pix.n)
        
        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ÙŠ
        if len(img_array.shape) == 3 and img_array.shape[2] == 3:
            gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
        else:
            gray = img_array
        
        # Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯
        barcodes = decode_barcode(gray)
        for barcode in barcodes:
            barcode_text = barcode.data.decode("utf-8", errors='ignore').strip()
            if barcode_text:
                logger.debug(f"ğŸ“· ÙˆØ¬Ø¯ Ø¨Ø§Ø±ÙƒÙˆØ¯ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø© (ØµÙØ­Ø© {page_num}): {barcode_text}")
                return barcode_text
        
        return None
        
    except Exception as e:
        logger.debug(f"âŒ ÙØ´Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯ Ù…Ù† Ø§Ù„ØµÙØ­Ø© {page_num}: {e}")
        return None


    def _split_pages_fast(self, doc, separator_barcode, total_pages):
    """ØªÙ‚Ø³ÙŠÙ… Ø³Ø±ÙŠØ¹ Ù„Ù„ØµÙØ­Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø°ÙƒÙŠØ©"""
        sections = []
        current_section = []
        
        # ÙØ­Øµ ÙƒÙ„ Ø§Ù„ØµÙØ­Ø§Øª (Ù…Ù‡Ù… Ù„ÙØµÙ„ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨Ø¯Ù‚Ø©)
        for page_num in range(total_pages):
            try:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø§Ø±ÙƒÙˆØ¯ Ù…Ù† Ø§Ù„ØµÙØ­Ø©
                barcode = self._extract_barcode_from_pdf_page(doc, page_num, dpi=72)
                
                # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ø°Ù‡ Ø§Ù„ØµÙØ­Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨Ø§Ø±ÙƒÙˆØ¯ Ø§Ù„ÙØ§ØµÙ„
                if barcode == separator_barcode:
                    # Ù‡Ø°Ù‡ ØµÙØ­Ø© ÙØ§ØµÙ„ - Ù†Ø¨Ø¯Ø£ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¬Ø¯ÙŠØ¯Ø©
                    if current_section:
                        # Ù†Ø­ÙØ¸ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
                        sections.append(current_section.copy())
                        current_section = []
                    # Ù„Ø§ Ù†Ø¶ÙŠÙ ØµÙØ­Ø© Ø§Ù„Ø¨Ø§Ø±ÙƒÙˆØ¯ Ø§Ù„ÙØ§ØµÙ„ Ù„Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©
                    continue
                else:
                    # ØµÙØ­Ø© Ø¹Ø§Ø¯ÙŠØ© - Ù†Ø¶ÙŠÙÙ‡Ø§ Ù„Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
                    current_section.append(page_num)
                    
            except Exception as e:
                logger.debug(f"Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ Ø§Ù„ØµÙØ­Ø© {page_num}: {e}")
                # ÙÙŠ Ø­Ø§Ù„Ø© Ø®Ø·Ø£ØŒ Ù†Ø¶ÙŠÙ Ø§Ù„ØµÙØ­Ø© Ù„Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
                current_section.append(page_num)
        
        # Ø¥Ø¶Ø§ÙØ© Ø¢Ø®Ø± Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ÙˆØ¬ÙˆØ¯Ø©
        if current_section:
            sections.append(current_section)
        
        # ØªØµÙÙŠØ© Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„ÙØ§Ø±ØºØ©
        cleaned_sections = [section for section in sections if section]
        
        logger.info(f"ğŸ”¢ ØªÙ… ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙØ­Ø§Øª Ø¥Ù„Ù‰ {len(cleaned_sections)} Ù…Ø¬Ù…ÙˆØ¹Ø©")
        for i, section in enumerate(cleaned_sections):
            logger.info(f"   Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© {i+1}: Ø§Ù„ØµÙØ­Ø§Øª {section}")
        
        return cleaned_sections
        
    def _expand_section(self, section_indices, checked_indices, break_point, total_pages):
        """ØªÙˆØ³ÙŠØ¹ Ù‚Ø³Ù… Ù„ÙŠØ´Ù…Ù„ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙØ­Ø§Øª"""
        if not section_indices:
            return []
        
        # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Ø·Ø§Ù‚ Ø§Ù„ØµÙØ­Ø§Øª
        start_page = min(section_indices)
        end_page = max(section_indices)
        
        # Ø¥Ø°Ø§ ÙƒØ§Ù† break_point Ù‚Ø¨Ù„ end_pageØŒ Ø§Ø³ØªØ®Ø¯Ù…Ù‡
        if break_point < end_page and break_point > start_page:
            end_page = break_point - 1
        
        # Ø§Ù„ØªÙˆØ³ÙŠØ¹
        expanded = []
        for page_num in range(start_page, min(end_page + 1, total_pages)):
            expanded.append(page_num)
        
        return expanded
    
    def _create_groups_ultra_fast(self, doc, sections, separator_barcode, upload):
    """Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¨Ø£Ù‚ØµÙ‰ Ø³Ø±Ø¹Ø©"""
    created_groups = []
    output_dir = Path(settings.PRIVATE_MEDIA_ROOT) / "groups"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    def extract_group_name(page_num):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø£ÙˆÙ„ ØµÙØ­Ø©"""
        try:
            page = doc[page_num]
            text = page.get_text("text")
            if text:
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ø³Ù…Ø§Ø¡ Ù…Ø­ØªÙ…Ù„Ø©
                patterns = [
                    r'Ø±Ù‚Ù…[:\s]*(\d+)',  # Ø±Ù‚Ù… Ø§Ù„Ù‚ÙŠØ¯
                    r'Ø±Ù‚Ù… Ø§Ù„Ø³Ù†Ø¯[:\s]*(\d+)',
                    r'Ø§Ù„ÙØ§ØªÙˆØ±Ø© Ø±Ù‚Ù…[:\s]*(\d+)',
                    r'Invoice[:\s]*(\d+)',
                    r'(\d{2}/\d{2}/\d{4})',  # ØªØ§Ø±ÙŠØ®
                ]
                
                for pattern in patterns:
                    matches = re.findall(pattern, text, re.IGNORECASE | re.ARABIC)
                    if matches:
                        return matches[0]
                
                # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø£ÙˆÙ„ Ø³Ø·Ø± Ù…Ù† Ø§Ù„Ù†Øµ
                lines = text.split('\n')
                for line in lines:
                    line = line.strip()
                    if line and len(line) > 3 and not line.isnumeric():
                        return line[:50]  # ØªÙ‚ØµÙŠØ± Ø¥Ø°Ø§ ÙƒØ§Ù† Ø·ÙˆÙŠÙ„Ø§Ù‹
        except:
            pass
        
        # Ø§Ø³Ù… Ø§ÙØªØ±Ø§Ø¶ÙŠ
        return f"Ù…Ø¬Ù…ÙˆØ¹Ø©_{page_num+1}"
    
    def create_single_group(idx, pages):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© ÙˆØ§Ø­Ø¯Ø©"""
        try:
            if not pages:
                return None
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø£ÙˆÙ„ ØµÙØ­Ø©
            group_name = extract_group_name(pages[0])
            
            # Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
            timestamp = datetime.now().strftime("%H%M%S")
            filename = f"{group_name}_{idx+1}_{timestamp}"
            filename = self._sanitize_filename(filename)
            filename_safe = f"{filename}.pdf"
            output_path = output_dir / filename_safe
            
            # Ø¥Ù†Ø´Ø§Ø¡ PDF Ø¬Ø¯ÙŠØ¯
            new_doc = fitz.open()
            for page_num in pages:
                if page_num < doc.page_count:
                    new_doc.insert_pdf(doc, from_page=page_num, to_page=page_num)
            
            # Ø­ÙØ¸ Ù…Ø¹ Ø¶ØºØ·
            new_doc.save(output_path, deflate=True, garbage=4, clean=True)
            new_doc.close()
            
            # Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            group = Group.objects.create(
                code=separator_barcode,
                pdf_path=f"groups/{filename_safe}",
                pages_count=len(pages),
                user=upload.user,
                upload=upload,
                filename=filename_safe,
                name=group_name  # Ø­ÙØ¸ Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬
            )
            
            logger.info(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© {idx+1}: {group_name} ({len(pages)} ØµÙØ­Ø©)")
            return group
            
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© {idx+1}: {e}")
            return None
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ
    with ThreadPoolExecutor(max_workers=self.MAX_WORKERS) as executor:
        futures = []
        for idx, pages in enumerate(sections):
            future = executor.submit(create_single_group, idx, pages)
            futures.append(future)
        
        # Ø¬Ù…Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø¹ ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø¯Ù…
        completed = 0
        for future in as_completed(futures):
            try:
                result = future.result(timeout=30)
                if result:
                    created_groups.append(result)
                    completed += 1
                    
                    # ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø¯Ù…
                    if len(sections) > 0:
                        progress = 60 + int((completed / len(sections)) * 40)
                        with self._lock:
                            upload.progress = min(progress, 99)
                            upload.save(update_fields=['progress'])
                            
            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù‚Ø³Ù…: {e}")
    
    return created_groups

    
    def _sanitize_filename(self, filename):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù"""
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø­Ø±Ù ØºÙŠØ± Ø§Ù„Ø¢Ù…Ù†Ø©
        filename = re.sub(r'[^\w\-_\.]', '_', filename)
        # ØªÙ‚ØµÙŠØ± Ø¥Ø°Ø§ Ø·Ø§Ù„
        if len(filename) > 80:
            name, ext = os.path.splitext(filename)
            filename = name[:75] + ext
        return filename or "document"
    
    def _delete_original_if_needed(self, pdf_path):
        """Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù†Ø§Ø¬Ø­Ø©"""
        try:
            if pdf_path.exists():
                # ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù Ø£ÙˆÙ„Ø§Ù‹
                file_size = pdf_path.stat().st_size
                if file_size > 50 * 1024 * 1024:  # Ø£ÙƒØ¨Ø± Ù…Ù† 50MB
                    logger.info(f"âš ï¸ Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ Ø§Ù„ÙƒØ¨ÙŠØ±: {file_size / (1024*1024):.1f}MB")
                    return
                
                pdf_path.unlink()
                logger.info(f"ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ: {pdf_path}")
        except Exception as e:
            logger.warning(f"âš ï¸ ÙØ´Ù„ Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ: {e}")

    def process_multiple_pdfs_async(self, uploads):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ø¯Ø© Ù…Ù„ÙØ§Øª Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†"""
        import asyncio
        import aiohttp
        
        async def process_upload_async(upload):
            """Ù…Ø¹Ø§Ù„Ø¬Ø© upload ÙˆØ§Ø­Ø¯Ø© Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†"""
            try:
                groups = await asyncio.to_thread(self.process_single_pdf, upload)
                return upload.id, {"success": True, "groups": groups}
            except Exception as e:
                return upload.id, {"success": False, "error": str(e)}
        
        async def main():
            """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠØ©"""
            tasks = [process_upload_async(upload) for upload in uploads]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            processed_results = {}
            for result in results:
                if isinstance(result, tuple) and len(result) == 2:
                    upload_id, data = result
                    processed_results[upload_id] = data
            
            return processed_results
        
        # ØªØ´ØºÙŠÙ„ ÙÙŠ loop Ø¬Ø¯ÙŠØ¯
        import asyncio
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            results = loop.run_until_complete(main())
        finally:
            loop.close()
        
        return results